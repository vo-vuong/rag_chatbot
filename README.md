# RAG Chatbot

A comprehensive Retrieval-Augmented Generation (RAG) chatbot built with Streamlit that enables intelligent document Q&A through advanced processing, OCR capabilities, and AI-powered retrieval.

## âœ¨ Key Features

- ğŸ¤– **Multi-LLM Support**: OpenAI models (GPT-4o, GPT-4o Mini, GPT-4 Turbo) with planned Gemini and local Ollama support
- ğŸ“„ **Advanced Document Processing**: PDF and CSV support with intelligent OCR and semantic chunking
- ğŸ’¾ **Vector Database**: Qdrant integration for efficient similarity search and collection management
- ğŸ”¤ **OCR Integration**: Tesseract OCR with 125+ language support including English and Vietnamese
- ğŸ”„ **Real-time Chat**: Context-aware conversations with RAG or LLM-only modes
- ğŸ—‚ï¸ **Data Management**: Create, explore, and manage vector collections with advanced filtering
- âš™ï¸ **Multi-tier Processing**: Auto-detection with robust fallback mechanisms

## ğŸš€ Quick Start

### Prerequisites
- Python 3.8+
- Conda (environment management)
- Docker & Docker Compose (for Qdrant)

### Installation

```bash
# 1. Clone and setup
git clone <repository-url>
cd rag_chatbot

# 2. Create conda environment
conda create -n rag_chatbot python=3.9 -y
conda activate rag_chatbot

# 3. Install dependencies
pip install -r requirements.txt

# 4. Setup environment
cp .env.example .env
# Edit .env with your OpenAI API key

# 5. Start Qdrant
docker-compose up -d

# 6. Run application
streamlit run app.py
```

Visit `http://localhost:8501` to access the application.

### Basic Workflow

1. **Setup**: Configure OpenAI API key in sidebar
2. **Upload**: Add PDF/CSV files via Upload page
3. **Process**: Choose processing strategy (Auto, Fast, High-Res, OCR)
4. **Chat**: Ask questions on main chat page
5. **Manage**: Use Data Management to explore collections

## ğŸ“‹ Document Processing

### Supported Formats
- **PDF**: Advanced processing with OCR, semantic chunking, and metadata extraction
- **CSV**: Intelligent processing with column-based grouping, enhanced chunking, and tab-based UI

### Processing Strategies
- **Auto**: Intelligent strategy detection (recommended)
- **Fast**: Quick text extraction for text-based PDFs
- **High Resolution**: OCR-enabled processing for image-based PDFs
- **OCR Only**: Force OCR processing for scanned documents
- **Fallback**: Basic extraction with pdfplumber

### CSV Processing Features
- **Column-based Grouping**: Intelligent chunking by selected columns
- **Memory Optimization**: Streaming processing for large CSV files
- **Enhanced UI**: Tab-based interface
- **File Pointer Management**: Robust file handling with seek(0) operations
- **Performance Monitoring**: Real-time processing statistics and benchmarking

## âš™ï¸ Configuration

### Environment Variables
```bash
# Required
OPENAI_API_KEY=your_openai_api_key_here

# Optional (with defaults)
QDRANT_HOST=localhost
QDRANT_PORT=6333
QDRANT_COLLECTION_NAME=rag_chatbot_collection
DEFAULT_LLM_MODEL=gpt-4o-mini
TEMPERATURE=0.7
```

### LLM Configuration
- **OpenAI**: GPT-4o, GPT-4o Mini, GPT-4 Turbo, GPT-3.5 Turbo
- **Gemini**: Google Gemini models (planned)
- **Local**: Ollama-hosted models (planned)

## ğŸ—ï¸ Architecture

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   Streamlit UI  â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Session Manager â”‚  (Singleton state management)
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚  Document Proc  â”‚  (Strategy pattern with OCR)
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚   Vector DB     â”‚  (Qdrant with collections)
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚   LLM Services  â”‚  (OpenAI, Gemini, Ollama)
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

## ğŸ“š Documentation

- **[Project Overview & PDR](docs/project-overview-pdr.md)**: Comprehensive requirements and specifications
- **[Codebase Summary](docs/codebase-summary.md)**: Detailed component documentation
- **[Code Standards](docs/code-standards.md)**: Development guidelines and best practices
- **[System Architecture](docs/system-architecture.md)**: Technical architecture and design patterns

## ğŸ³ Docker Management

```bash
# Start services
docker-compose up -d

# View logs
docker-compose logs -f qdrant

# Stop services
docker-compose down

# Restart Qdrant
docker-compose restart qdrant
```

## ğŸ“Š Usage Tips

### PDF Processing Best Practices
- **Text-based PDFs**: Use "Fast Processing" for speed
- **Image-based PDFs**: Use "High Resolution" for quality
- **Scanned documents**: Use "OCR Processing" for extraction
- **Large files**: Allow extra time for OCR processing

### Search Strategies
- **Vector Search**: Best for semantic similarity
- **Keywords Search**: Traditional text matching
- **Hybrid Search**: Combines both approaches

## ğŸ”§ Development

### Project Structure
```
rag_chatbot/
â”œâ”€â”€ app.py                           # Main Streamlit application
â”œâ”€â”€ backend/                         # Core business logic
â”‚   â”œâ”€â”€ session_manager.py           # Session state management
â”‚   â”œâ”€â”€ document_processor.py        # Document processing orchestrator
â”‚   â”œâ”€â”€ collection_management.py     # Vector database collection management
â”‚   â”œâ”€â”€ chunking/                    # Document chunking strategies
â”‚   â”‚   â”œâ”€â”€ semantic_chunker.py      # Semantic text chunking
â”‚   â”‚   â”œâ”€â”€ csv_grouping_chunker.py  # CSV-specific chunking
â”‚   â”‚   â””â”€â”€ chunk_result.py          # Chunking result data structures
â”‚   â”œâ”€â”€ embeddings/                  # Vector embedding strategies
â”‚   â”‚   â”œâ”€â”€ embedding_strategy.py    # Embedding abstraction layer
â”‚   â”‚   â”œâ”€â”€ embedding_factory.py     # Embedding provider factory
â”‚   â”‚   â”œâ”€â”€ openai_embeddings.py     # OpenAI embedding implementation
â”‚   â”‚   â””â”€â”€ local_embeddings.py      # Local model embeddings (planned)
â”‚   â”œâ”€â”€ llms/                        # Large Language Model integrations
â”‚   â”‚   â”œâ”€â”€ llm_strategy.py          # LLM abstraction
â”‚   â”‚   â”œâ”€â”€ llm_factory.py           # LLM provider factory
â”‚   â”‚   â”œâ”€â”€ openai_llm.py            # OpenAI LLM implementation
â”‚   â”‚   â”œâ”€â”€ online_llm.py            # Online LLM management
â”‚   â”‚   â”œâ”€â”€ gemini_llm.py            # Google Gemini integration (planned)
â”‚   â”‚   â”œâ”€â”€ local_llm.py             # Local LLM support
â”‚   â”‚   â””â”€â”€ ollama_manager.py        # Ollama integration
â”‚   â”œâ”€â”€ ocr/                         # Optical Character Recognition
â”‚   â”‚   â””â”€â”€ tesseract_ocr.py         # Tesseract OCR implementation
â”‚   â”œâ”€â”€ strategies/                  # Document processing strategies
â”‚   â”‚   â”œâ”€â”€ interfaces.py            # Strategy interface definitions
â”‚   â”‚   â”œâ”€â”€ pdf_strategy.py          # PDF processing strategy
â”‚   â”‚   â”œâ”€â”€ csv_strategy.py          # CSV processing strategy
â”‚   â”‚   â””â”€â”€ results.py               # Processing result structures
â”‚   â”œâ”€â”€ prompts/                     # Prompt management system
â”‚   â”‚   â”œâ”€â”€ prompt_manager.py        # Prompt template manager
â”‚   â”‚   â”œâ”€â”€ prompt_template.py       # Template definition
â”‚   â”‚   â””â”€â”€ prompt_builder.py        # Dynamic prompt construction
â”‚   â”œâ”€â”€ utils/                       # Utility functions
â”‚   â”‚   â””â”€â”€ csv_optimizer.py         # CSV processing optimizations
â”‚   â”œâ”€â”€ errors/                      # Error handling
â”‚   â”‚   â””â”€â”€ csv_errors.py            # CSV-specific error types
â”‚   â””â”€â”€ vector_db/                   # Vector database integration
â”‚       â””â”€â”€ qdrant_manager.py        # Qdrant client wrapper
â”œâ”€â”€ ui/                              # Streamlit UI components
â”‚   â”œâ”€â”€ chat_main.py                 # Main chat interface
â”‚   â”œâ”€â”€ data_upload.py               # Document upload and processing UI
â”‚   â”œâ”€â”€ data_management.py           # Collection management UI
â”‚   â”œâ”€â”€ sidebar_navigation.py        # Navigation and configuration sidebar
â”‚   â”œâ”€â”€ components.py                # Reusable UI components
â”‚   â””â”€â”€ llm_setup.py                 # LLM configuration interface
â”œâ”€â”€ config/                          # Configuration management
â”‚   â””â”€â”€ constants.py                 # Application constants and defaults
â”œâ”€â”€ docs/                            # Documentation
â”œâ”€â”€ requirements.txt                 # Python dependencies
â”œâ”€â”€ docker-compose.yml              # Qdrant container configuration
â”œâ”€â”€ .env.example                     # Environment variables template
â””â”€â”€ .gitignore                       # Git ignore patterns
```
